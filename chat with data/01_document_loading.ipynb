{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8c95a56-f6ea-4e2d-9a1f-515cc27e7c9f",
   "metadata": {},
   "source": [
    "# Document Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ecaf727-6b0c-44da-9620-8673584a61a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Retrieval augmented generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d01b201-ce96-4d59-a3ee-175640bfc34f",
   "metadata": {
    "tags": []
   },
   "source": [
    "In retrieval augmented generation (RAG), an LLM retrieves contextual documents from an external dataset as part of its execution. \n",
    "\n",
    "This is useful if we want to ask question about specific documents (e.g., our PDFs, a set of videos, etc). \n",
    "\n",
    "\n",
    "![overview.jpg](overview.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0bca2e-e76a-4a54-9199-36880737570a",
   "metadata": {},
   "source": [
    "![data_loaders.png](attachment/data_loaders.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53f7728b-f613-4eef-bd3d-73a5af37cd39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#! pip install langchain\n",
    "\n",
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f98eaa5-1c0b-4815-8c5b-af2372db00e9",
   "metadata": {},
   "source": [
    "## PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e62b80c3-4908-452e-b769-62f56887bdf3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (88321209.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    Let's load a PDF [transcript](https://see.stanford.edu/materials/aimlcs229/transcripts/MachineLearning-Lecture01.pdf) from Andrew Ng's famous CS229 course! These documents are the result of automated transcription so words and sentences are sometimes split unexpectedly.\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Let's load a PDF [transcript](https://see.stanford.edu/materials/aimlcs229/transcripts/MachineLearning-Lecture01.pdf) from Andrew Ng's famous CS229 course! These documents are the result of automated transcription so words and sentences are sometimes split unexpectedly.\n",
    "\n",
    "# The course will show the pip installs you would need to install packages on your own machine.\n",
    "# These packages are already installed on this platform and should not be run again.\n",
    "#! pip install pypdf \n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"docs/cs229_lectures/MachineLearning-Lecture01.pdf\")\n",
    "pages = loader.load()\n",
    "\n",
    "Each page is a `Document`.\n",
    "\n",
    "A `Document` contains text (`page_content`) and `metadata`.\n",
    "\n",
    "len(pages)\n",
    "\n",
    "page = pages[0]\n",
    "\n",
    "print(page.page_content[0:500])\n",
    "\n",
    "page.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bd38b5-0da3-4eb7-a790-ea3582be4f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## YouTube\n",
    "\n",
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers import OpenAIWhisperParser\n",
    "from langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader\n",
    "\n",
    "# ! pip install yt_dlp\n",
    "# ! pip install pydub\n",
    "\n",
    "**Note**: This can take several minutes to complete.\n",
    "\n",
    "url=\"https://www.youtube.com/watch?v=jGwO_UgTS7I\"\n",
    "save_dir=\"docs/youtube/\"\n",
    "loader = GenericLoader(\n",
    "    YoutubeAudioLoader([url],save_dir),\n",
    "    OpenAIWhisperParser()\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "docs[0].page_content[0:500]\n",
    "\n",
    "## URLs\n",
    "\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://github.com/basecamp/handbook/blob/master/37signals-is-you.md\")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "print(docs[0].page_content[:500])\n",
    "\n",
    "## Notion\n",
    "\n",
    "Follow steps [here](https://python.langchain.com/docs/modules/data_connection/document_loaders/integrations/notion) for an example Notion site such as [this one](https://yolospace.notion.site/Blendle-s-Employee-Handbook-e31bff7da17346ee99f531087d8b133f):\n",
    "\n",
    "* Duplicate the page into your own Notion space and export as `Markdown / CSV`.\n",
    "* Unzip it and save it as a folder that contains the markdown file for the Notion page.\n",
    " \n",
    "\n",
    "![image.png](./img/image.png)\n",
    "\n",
    "from langchain.document_loaders import NotionDirectoryLoader\n",
    "loader = NotionDirectoryLoader(\"docs/Notion_DB\")\n",
    "docs = loader.load()\n",
    "\n",
    "print(docs[0].page_content[0:200])\n",
    "\n",
    "docs[0].metadata\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai_env",
   "language": "python",
   "name": "genai_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
